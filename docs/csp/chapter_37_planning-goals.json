{
  "metadata": {
    "title": "A Formal Theory of Commonsense Psychology: How People Think People Think",
    "authors": "Andrew S. Gordon and Jerry R. Hobbs",
    "publisher": "Cambridge University Press",
    "year": 2017,
    "chapter": 37,
    "chapter_title": "Planning Goals",
    "extraction_date": "2025-01-08",
    "axiom_count": 31,
    "description": "Chapter 37 axioms covering planning constraints, preferences, and goal optimization including value minimization/maximization, enabling/blocking events, and plan instantiation",
    "notation": "First-order logic with defeasible reasoning, preference orderings, and plan optimization"
  },
  "axioms": [
    {
      "id": "37.1",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 397,
      "axiom_number": "(37.1)",
      "title": "Definition of addGoalToPlan",
      "fol": "(forall (a g2 p1 p2) (iff (addGoalToPlan a g2 p1 p2) (exists (g1 g) (and (plan p1 a g1)(plan p2 a g)(and' g g1 g2) (subplan p1 p2)))))",
      "english": "Agent a adds goal g2 to plan p1 to produce p2. This happens when p2 is a plan to achieve g2 in addition to p1's top-level goal g1 and when the original plan p1 is a subplan of the resulting plan p2.",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["addGoalToPlan", "plan", "and'", "subplan"],
      "variables": ["a", "g2", "p1", "p2", "g1", "g"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.2",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 397,
      "axiom_number": "(37.2)",
      "title": "Definition of planningConstraint",
      "fol": "(forall (e1 a p) (iff (planningConstraint e a p) (exists (p2) (addGoalToPlan a e p p2))))",
      "english": "Eventuality e is a constraint on agent a's plan p exactly when a adds e as a goal to p. People often have hard constraints for plans that they would consider to be successful.",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["planningConstraint", "addGoalToPlan"],
      "variables": ["e1", "a", "p", "e", "p2"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.3",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 398,
      "axiom_number": "(37.3)",
      "title": "Preference type constraints",
      "fol": "(forall (a e1 e2 p) (if (prefer a e1 e2 p) (and (agent a)(eventuality e1)(eventuality e2) (exists (g) (plan p a g)))))",
      "english": "The predication (prefer a e1 e2 p) says agent a prefers eventuality e1 to eventuality e2 in carrying out plan p. Agent must be valid, both eventualities must exist, and there must be a plan.",
      "complexity": "simple",
      "pattern": "type_constraint",
      "predicates": ["prefer", "agent", "eventuality", "plan"],
      "variables": ["a", "e1", "e2", "p", "g"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.4",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 398,
      "axiom_number": "(37.4)",
      "title": "Defeasible preference incompatibility",
      "fol": "(forall (a e1 e2 p) (if (and (prefer a e1 e2 p)(etc)) (exists (e)(and (not' e e1)(imply e2 e)))))",
      "english": "The two eventualities should be incompatible; otherwise there will be no reason to have to choose one over the other. Defeasibly, e2 implies the negation e of e1.",
      "complexity": "simple",
      "pattern": "defeasible_rule",
      "predicates": ["prefer", "not'", "imply"],
      "variables": ["a", "e1", "e2", "p", "e"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.5",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 398,
      "axiom_number": "(37.5)",
      "title": "Preferred option adoption when possible",
      "fol": "(forall (a e1 e2 p s1 s2 s3 s0) (if (and (prefer a e1 e2 p) (cwu s1 a)(eventualitiesOf s2 s1)(subgoalsOf s3 p) (union s0 s2 s3) (possible e1 s0)(etc)) (exists (p2) (addGoalToPlan a e1 p p2))))",
      "english": "Preferences are 'goals in waiting.' If they do not contradict any real goals and they are otherwise possible, they will normally be adopted as goals. Agent a prefers e1 to e2 while executing plan p, and if e1 is possible given current world understanding and plan subgoals, then e1 will be incorporated as a goal.",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["prefer", "cwu", "eventualitiesOf", "subgoalsOf", "union", "possible", "addGoalToPlan"],
      "variables": ["a", "e1", "e2", "p", "s1", "s2", "s3", "s0", "p2"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.6",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 399,
      "axiom_number": "(37.6)",
      "title": "Dispreferred option adoption when preferred impossible",
      "fol": "(forall (a e1 e2 p s1 s2 s3 s0) (if (and (prefer a e1 e2 p) (cwu s1 a)(eventualitiesOf s2 s1)(subgoalsOf s3 p) (union s0 s2 s3) (not (possible e1 s0)) (possible e2 s0)(etc)) (exists (p2) (addGoalToPlan a e2 p p2))))",
      "english": "In normal usage, we will adopt the dispreferred element if the preferred one is not possible. Lines 1-4 are the same as in the previous axiom. Line 5 says e1 is not possible. Line 6 says that the dispreferred item e2 is possible. Line 8 says that in these circumstances, e2 will be incorporated into the plan.",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["prefer", "cwu", "eventualitiesOf", "subgoalsOf", "union", "possible", "addGoalToPlan"],
      "variables": ["a", "e1", "e2", "p", "s1", "s2", "s3", "s0", "p2"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.7",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 399,
      "axiom_number": "(37.7)",
      "title": "Forced choice preference adoption",
      "fol": "(forall (a e1 e2 p s1 s2 s3 s0 e3 t t1) (if (and (prefer a e1 e2 p) (cwu0 s1 a t)(Now t) (eventualitiesOf s2 s1)(subgoalsOf s3 p) (union s0 s2 s3) (possible e1 s0)(possible e2 s0) (or' e3 e1 e2)(atTime e3 t1)(before t t1)(etc)) (exists (p2 e4) (or (and (not (badFor e1 a))(addGoalToPlan a e1 p p2)) (and (badFor e1 a)(not' e4 e2)(addGoalToPlan a e4 p p2))))))",
      "english": "We can strengthen the preference axiom in forced choice situations where both options are possible and one is going to occur anyway. If the preferred option is bad for you, then the goal you add is the negation of the dispreferred option. Line 6 says both options are possible. Line 7 says that one of them is going to happen anyway. In line 9 we add the preferred option if it is not bad for us. If it is, then in line 10 we add the negation of the dispreferred option.",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["prefer", "cwu0", "Now", "eventualitiesOf", "subgoalsOf", "union", "possible", "or'", "atTime", "before", "badFor", "not'", "addGoalToPlan"],
      "variables": ["a", "e1", "e2", "p", "s1", "s2", "s3", "s0", "e3", "t", "t1", "p2", "e4"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.8",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 399,
      "axiom_number": "(37.8)",
      "title": "Preference antisymmetry",
      "fol": "(forall (a e1 e2 p) (if (prefer a e1 e2 p)(not (prefer a e2 e1 p))))",
      "english": "Preference is a partial ordering. Hence, it is antisymmetric.",
      "complexity": "simple",
      "pattern": "ordering_property",
      "predicates": ["prefer"],
      "variables": ["a", "e1", "e2", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.9",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 399,
      "axiom_number": "(37.9)",
      "title": "Preference transitivity",
      "fol": "(forall (a e1 e2 e3 p) (if (and (prefer a e1 e2 p)(prefer a e2 e3 p)) (prefer a e1 e3 p)))",
      "english": "Preference is also transitive.",
      "complexity": "simple",
      "pattern": "ordering_property",
      "predicates": ["prefer"],
      "variables": ["a", "e1", "e2", "e3", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.10",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 400,
      "axiom_number": "(37.10)",
      "title": "Definition of prefer0",
      "fol": "(forall (a e1 p) (iff (prefer0 a e1 p) (exists (e2) (and (not' e2 e1)(prefer a e1 e2 p)))))",
      "english": "It will be convenient to have a predicate meaning that the agent prefers a situation e1 to its absence.",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["prefer0", "not'", "prefer"],
      "variables": ["a", "e1", "p", "e2"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.11",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 400,
      "axiom_number": "(37.11)",
      "title": "Value-based preference",
      "fol": "(forall (e1 e2 a p) (if (and (moreValuable e1 e2 a)(etc)) (prefer a e1 e2 p)))",
      "english": "If e1 is more valuable than e2, then defeasibly a will prefer e1 to e2.",
      "complexity": "simple",
      "pattern": "defeasible_rule",
      "predicates": ["moreValuable", "prefer"],
      "variables": ["e1", "e2", "a", "p"],
      "quantifiers": ["forall"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.12",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.1",
      "page": 400,
      "axiom_number": "(37.12)",
      "title": "Cost-based preference",
      "fol": "(forall (e1e2 a p) (if (and (moreCostly e1 e2 a)(etc)) (prefer a e2 e1 p)))",
      "english": "If e1 is more costly than e2, then defeasibly a will prefer e2 to e1.",
      "complexity": "simple",
      "pattern": "defeasible_rule",
      "predicates": ["moreCostly", "prefer"],
      "variables": ["e1e2", "a", "p"],
      "quantifiers": ["forall"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.13",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.2",
      "page": 400,
      "axiom_number": "(37.13)",
      "title": "Definition of preferAvoidAction",
      "fol": "(forall (a e p) (iff (preferAvoidAction a e p) (exists (e1) (and (not' e1 e)(prefer0 a e1 p)))))",
      "english": "An agent a prefers to avoid action e in plan p exactly when a prefers to include its negation in the plan. This captures phrases like 'try to avoid' and 'only as a last resort.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferAvoidAction", "not'", "prefer0"],
      "variables": ["a", "e", "p", "e1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.14",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 401,
      "axiom_number": "(37.14)",
      "title": "Definition of preferEnableEvent",
      "fol": "(forall (a e p) (iff (preferEnableEvent a e p) (forall (e1) (if (enable e1 e)(prefer0 a e1 p)))))",
      "english": "One can prefer to work toward plans that enable an event to occur, as in 'set the stage for.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferEnableEvent", "enable", "prefer0"],
      "variables": ["a", "e", "p", "e1"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.15",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 401,
      "axiom_number": "(37.15)",
      "title": "Definition of preferBlockEvent",
      "fol": "(forall (a e p) (iff (preferBlockEvent a e p) (forall (e1) (if (prevent e1 e)(prefer0 a e1 p)))))",
      "english": "One can prefer to work toward plans that prevent an event from occurring, as in 'safeguard against.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferBlockEvent", "prevent", "prefer0"],
      "variables": ["a", "e", "p", "e1"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.16",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 401,
      "axiom_number": "(37.16)",
      "title": "Definition of preferEnableThreat",
      "fol": "(forall (a e p) (iff (preferEnableThreat a e p) (and (preferEnableEvent a e p)(threat0 e a))))",
      "english": "One can prefer to work toward plans that ensure a threat will actually occur, as in 'set one up to fail.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferEnableThreat", "preferEnableEvent", "threat0"],
      "variables": ["a", "e", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.17",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 401,
      "axiom_number": "(37.17)",
      "title": "Definition of preferBlockThreat",
      "fol": "(forall (a e p) (iff (preferBlockThreat a e p) (and (preferBlockEvent a e p)(threat0 e a))))",
      "english": "One can prefer to work toward plans that ensure a threat will not actually occur, as in 'take preemptive action' and 'alleviate the risk.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferBlockThreat", "preferBlockEvent", "threat0"],
      "variables": ["a", "e", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.18",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 401,
      "axiom_number": "(37.18)",
      "title": "Definition of preferEnableTransfer",
      "fol": "(forall (a e p) (iff (preferEnableTransfer a e p) (exists (x y z) (and (move' e x y z)(physobj x) (preferEnableEvent a e p)))))",
      "english": "One can prefer to work toward plans that allow a physical transfer through space, as in 'clear the path' and 'remove obstacles.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferEnableTransfer", "move'", "physobj", "preferEnableEvent"],
      "variables": ["a", "e", "p", "x", "y", "z"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.19",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 401,
      "axiom_number": "(37.19)",
      "title": "Definition of preferBlockTransfer",
      "fol": "(forall (a e p) (iff (preferBlockTransfer a e p) (exists (x y z) (and (move' e x y z)(physobj x) (preferBlockEvent a e p)))))",
      "english": "One can prefer to work toward plans that prevent a physical transfer through space, as in 'obstruct' and 'prevent from leaving.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferBlockTransfer", "move'", "physobj", "preferBlockEvent"],
      "variables": ["a", "e", "p", "x", "y", "z"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.20",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 402,
      "axiom_number": "(37.20)",
      "title": "Definition of preferEnableAgency",
      "fol": "(forall (a b e p) (iff (preferEnableAgency a b e p) (and (agentOf b e)(preferEnableEvent a e p))))",
      "english": "One can prefer to work toward plans that enable a different agent to act, as in 'make it possible for.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferEnableAgency", "agentOf", "preferEnableEvent"],
      "variables": ["a", "b", "e", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.21",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 402,
      "axiom_number": "(37.21)",
      "title": "Definition of preferBlockAgency",
      "fol": "(forall (a b e p) (iff (preferBlockAgency a b e p) (and (agentOf b e)(preferBlockEvent a e p))))",
      "english": "One can prefer to work toward plans that block a different agent from acting, as in 'paralyze' and 'keep one on a short leash.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferBlockAgency", "agentOf", "preferBlockEvent"],
      "variables": ["a", "b", "e", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.22",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 402,
      "axiom_number": "(37.22)",
      "title": "Definition of preferEnableOtherAgentGoalSatisfaction",
      "fol": "(forall (a b e p) (iff (preferEnableOtherAgentGoalSatisfaction a b e p) (exists (g1) (and (goal g1 b)(enable e g1) (preferEnableEvent a e p)))))",
      "english": "One can prefer to work toward plans that enable others to achieve their goals, as in 'make someone happy.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferEnableOtherAgentGoalSatisfaction", "goal", "enable", "preferEnableEvent"],
      "variables": ["a", "b", "e", "p", "g1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.23",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.3",
      "page": 402,
      "axiom_number": "(37.23)",
      "title": "Definition of preferBlockOtherAgentGoalSatisfaction",
      "fol": "(forall (a b e p) (iff (preferBlockOtherAgentGoalSatisfaction a b e p) (exists (g1) (and (goal g1 b)(enable e g1) (preferBlockEvent a e p)))))",
      "english": "One can prefer to work toward plans that prevent others from achieving their goals, as in 'thwart' and 'derail.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferBlockOtherAgentGoalSatisfaction", "goal", "enable", "preferBlockEvent"],
      "variables": ["a", "b", "e", "p", "g1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.24",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.4",
      "page": 402,
      "axiom_number": "(37.24)",
      "title": "Definition of preferMinimizeValue",
      "fol": "(forall (a v p) (iff (preferMinimizeValue a v p) (forall (e1 e2 x1 x2 s) (if (and (at' e1 v x1 s)(at' e2 v x2 s) (lts x1 x2 s)) (prefer a e1 e2 p)))))",
      "english": "One can prefer to try to minimize a value that is part of a plan, as illustrated in 'less is more,' 'be conservative,' and 'frugal.' Lines 4-7 specify conditions e1 and e2, saying that e1 is the eventuality of some value v being at point x1 on some scale s, e2 is the eventuality of v being at x2 on s, where x1 is less than x2 on the scale. Under these circumstances, agent a will prefer e1 to e2.",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["preferMinimizeValue", "at'", "lts", "prefer"],
      "variables": ["a", "v", "p", "e1", "e2", "x1", "x2", "s"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.25",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.4",
      "page": 403,
      "axiom_number": "(37.25)",
      "title": "Definition of preferMaximizeValue",
      "fol": "(forall (a v p) (iff (preferMaximizeValue a v p) (forall (e1 e2 x1 x2 s) (if (and (at' e1 v x1 s)(at' e2 v x2 s) (lts x2 x1 s)) (prefer a e1 e2 p)))))",
      "english": "One can prefer to try to maximize a value that is part of a plan, as illustrated in the phrases 'bigger is better,' 'as much as possible,' and 'be liberal with.' This definition is the same as the previous one, except x1 and x2 are reversed in line 5.",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["preferMaximizeValue", "at'", "lts", "prefer"],
      "variables": ["a", "v", "p", "e1", "e2", "x1", "x2", "s"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.26",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.4",
      "page": 403,
      "axiom_number": "(37.26)",
      "title": "Definition of preferMinimizeDuration",
      "fol": "(forall (a p) (iff (preferMinimizeDuration a p) (exists (d u) (and (durationOf d p u) (preferMinimizeValue a d p)))))",
      "english": "Among the values one can seek to minimize or maximize are the durations of activities and events. Thus, one can prefer to try to minimize the overall duration of a plan, as in 'time is of the essence' and 'not waste time.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferMinimizeDuration", "durationOf", "preferMinimizeValue"],
      "variables": ["a", "p", "d", "u"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.27",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.4",
      "page": 403,
      "axiom_number": "(37.27)",
      "title": "Definition of preferMaximizeDuration",
      "fol": "(forall (a p) (iff (preferMaximizeDuration a p) (exists (d u) (and (durationOf d p u) (preferMaximizeValue a d p)))))",
      "english": "One can prefer to try to maximize the overall duration of a plan, as in 'prolong' and 'make it last.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["preferMaximizeDuration", "durationOf", "preferMaximizeValue"],
      "variables": ["a", "p", "d", "u"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.28",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.5",
      "page": 403,
      "axiom_number": "(37.28)",
      "title": "Definition of locateThing",
      "fol": "(forall (a x p) (iff (locateThing a x p) (exists (e p2 e1 g) (and (plan p a g)(addGoalToPlan a e p p2)(arg* x e) (imply e e1)(wh' e1 x g)))))",
      "english": "The expression (locateThing a x p) means that agent a instantiates unspecified entity x in plan p. Line 4 says that p is a plan for achieving g and agent a adds to that plan as a constraint a property e of x. Line 5 says that e implies a property e1 that enables x to be identified. Sometimes unspecified things must be instantiated for plans to be complete, as in 'locate,' 'search for,' and 'get one's hands on.'",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["locateThing", "plan", "addGoalToPlan", "arg*", "imply", "wh'"],
      "variables": ["a", "x", "p", "e", "p2", "e1", "g"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "37.29",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.5",
      "page": 404,
      "axiom_number": "(37.29)",
      "title": "Definition of locateAgent",
      "fol": "(forall (a x p) (iff (locateAgent a x p) (and (person x)(locateThing a x p))))",
      "english": "Sometimes unspecified people must be instantiated for plans to be complete, as in 'find someone to' and 'fill the job.'",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["locateAgent", "person", "locateThing"],
      "variables": ["a", "x", "p"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.30",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.5",
      "page": 404,
      "axiom_number": "(37.30)",
      "title": "Definition of locateLocation",
      "fol": "(forall (a x p) (iff (locateLocation a x p) (exists (y s e) (and (atLoc y x s)(arg* y e)(subgoalIn e p) (locateThing a x p)))))",
      "english": "Sometimes unspecified locations must be instantiated for plans to be complete, as in 'find a place where.' There is no such thing as a location per se. Something is the location of something else, indicated by the atLoc relation. Thus, to identify a location crucial to the execution of a plan is to recognize or decide upon the location of an entity that is an argument of or is involved in one of the subgoals of the plan.",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["locateLocation", "atLoc", "arg*", "subgoalIn", "locateThing"],
      "variables": ["a", "x", "p", "y", "s", "e"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "37.31",
      "chapter": 37,
      "chapter_title": "Planning Goals",
      "section": "37.6",
      "page": 404,
      "axiom_number": "(37.31)",
      "title": "Definition of preferMaintainPlanProgress",
      "fol": "(forall (a p) (iff (preferMaintainPlanProgress a p) (forall (e e1) (if (and (subgoalIn e p)(changeFrom' e1 e)) (exists (e2) (and (not' e2 e1)(prefer0 a e2 p)))))))",
      "english": "One can (and generally does) prefer to work toward plans that maintain the progress that has already been achieved. This is illustrated in the phrases 'avoid backpedaling' and 'keep moving forward.' That is, if e is a subgoal of the plan, agent a prefers not to change it. In cases where a previously achieved state must be undone for the plan to succeed, the preference will be overridden.",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["preferMaintainPlanProgress", "subgoalIn", "changeFrom'", "not'", "prefer0"],
      "variables": ["a", "p", "e", "e1", "e2"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    }
  ],
  "pattern_distribution": {
    "definition": 25,
    "defeasible_rule": 4,
    "type_constraint": 1,
    "ordering_property": 2
  },
  "complexity_distribution": {
    "simple": 21,
    "moderate": 7,
    "complex": 3
  },
  "domain_distribution": {
    "psychology": 31
  },
  "predicate_frequency": {
    "forall": 31,
    "iff": 25,
    "if": 6,
    "and": 31,
    "exists": 21,
    "prefer": 14,
    "addGoalToPlan": 6,
    "plan": 6,
    "prefer0": 8,
    "preferEnableEvent": 7,
    "preferBlockEvent": 5,
    "not'": 8,
    "at'": 4,
    "lts": 2,
    "enable": 4,
    "prevent": 2,
    "agentOf": 2,
    "goal": 2,
    "move'": 2,
    "physobj": 2,
    "durationOf": 2,
    "preferMinimizeValue": 2,
    "preferMaximizeValue": 2,
    "locateThing": 3,
    "person": 1,
    "atLoc": 1,
    "arg*": 2,
    "subgoalIn": 2,
    "changeFrom'": 1,
    "wh'": 1,
    "imply": 2,
    "threat0": 2,
    "badFor": 2,
    "moreValuable": 1,
    "moreCostly": 1,
    "cwu": 2,
    "cwu0": 1,
    "eventualitiesOf": 3,
    "subgoalsOf": 3,
    "union": 3,
    "possible": 5,
    "or'": 1,
    "atTime": 1,
    "before": 1,
    "Now": 1,
    "etc": 6
  },
  "conversion_notes": {
    "reified_predicates": "Extensive use of primed predicates for mental states and temporal relations: and', not', move', changeFrom', wh', at'",
    "defeasible_reasoning": "6 axioms use (etc) condition for non-monotonic preference adoption and value-based reasoning",
    "preference_framework": "Comprehensive preference theory with partial ordering properties (antisymmetric, transitive)",
    "plan_optimization": "Systematic treatment of plan constraints vs. soft preferences with adoption conditions",
    "cross_references": "Heavy integration with plan theory (Chapter 31), goal theory (Chapter 28), scale theory (Chapter 12), and value theory",
    "planning_constraints": "Distinction between hard constraints (must be satisfied) and soft preferences (adopted when possible)",
    "value_optimization": "Systematic treatment of minimization/maximization preferences for various plan aspects",
    "instantiation_framework": "Plan completion through locating unspecified entities, agents, and locations"
  },
  "file_format_notes": {
    "axiom_numbering": "Sequential numbering from 37.1 to 37.31",
    "logical_structure": "Mix of simple definitions and complex nested quantification, especially in preference adoption axioms",
    "predicate_consistency": "Consistent use of preference terminology with clear semantic distinctions between preference types",
    "defeasibility_markers": "Proper identification of defeasible rules using (etc) predicate in preference adoption and value-based reasoning",
    "reification_patterns": "Systematic reification of mental states, temporal relations, and physical movements",
    "preference_hierarchy": "Clear progression from basic preferences through specialized preference types to optimization strategies"
  }
}