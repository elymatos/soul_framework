{
  "metadata": {
    "title": "A Formal Theory of Commonsense Psychology: How People Think People Think",
    "authors": "Andrew S. Gordon and Jerry R. Hobbs",
    "publisher": "Cambridge University Press",
    "year": 2017,
    "chapter": 25,
    "chapter_title": "Explanation",
    "extraction_date": "2025-01-08",
    "axiom_count": 22,
    "description": "Chapter 25 axioms covering explanations, mysteries, explanation processes, and explanation failures",
    "notation": "First-order logic with reified eventualities and defeasible reasoning"
  },
  "axioms": [
    {
      "id": "25.1",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 299,
      "axiom_number": "(25.1)",
      "title": "Agents have the ability to explain some eventualities",
      "fol": "(forall (a c) (if (and (agent a)(cwu c a)) (exists (e0 e e1) (and (able a e0 c)(explain' e0 a e e1)))))",
      "english": "For any agent with current world understanding c, there exist some eventualities that the agent is able to explain",
      "complexity": "moderate",
      "pattern": "existence_claim",
      "predicates": ["agent", "cwu", "able", "explain'"],
      "variables": ["a", "c", "e0", "e", "e1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.2",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 299,
      "axiom_number": "(25.2)",
      "title": "Persons defeasibly explain eventualities",
      "fol": "(forall (a) (if (and (person a)(etc)) (exists (e e1)(explain a e e1))))",
      "english": "Defeasibly, for any person, there are eventualities that they really do explain",
      "complexity": "simple",
      "pattern": "defeasible_rule",
      "predicates": ["person", "explain", "etc"],
      "variables": ["a", "e", "e1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.3",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 299,
      "axiom_number": "(25.3)",
      "title": "Definition of mystery",
      "fol": "(forall (e a c) (iff (and (mystery e a)(cwu c a)) (and (agent a)(eventuality e) (not (exists (e1 e0) (and (able a e0 c) (explain' e0 a e e1)))))))",
      "english": "An eventuality is a mystery for an agent if the agent is not able to explain it within their current world understanding",
      "complexity": "complex",
      "pattern": "definition",
      "predicates": ["mystery", "cwu", "agent", "eventuality", "able", "explain'"],
      "variables": ["e", "a", "c", "e1", "e0"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.4",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 300,
      "axiom_number": "(25.4)",
      "title": "Persons have mysteries",
      "fol": "(forall (a) (if (person a) (exists (e) (mystery e a))))",
      "english": "For any person, there are eventualities that are mysteries to them",
      "complexity": "simple",
      "pattern": "existence_claim",
      "predicates": ["person", "mystery"],
      "variables": ["a", "e"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.5",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 300,
      "axiom_number": "(25.5)",
      "title": "Agents defeasibly have goals to explain",
      "fol": "(forall (a) (if (and (agent a) (etc)) (exists (e0 e e1) (and (goal e0 a)(explain' e0 a e e1)))))",
      "english": "Defeasibly, agents have goals to explain certain eventualities",
      "complexity": "moderate",
      "pattern": "defeasible_rule",
      "predicates": ["agent", "etc", "goal", "explain'"],
      "variables": ["a", "e0", "e", "e1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.6",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 300,
      "axiom_number": "(25.6)",
      "title": "Eventualities can have multiple possible explanations",
      "fol": "(forall (a c) (if (and (agent a)(cwu c a)) (exists (e e1 e2 e3 e4) (and (explain' e3 a e e1)(explain' e4 a e e2) (nequal e1 e2)(possible e3 c)(possible e4 c)))))",
      "english": "For any agent, there exist eventualities that have multiple different possible explanations",
      "complexity": "complex",
      "pattern": "existence_claim",
      "predicates": ["agent", "cwu", "explain'", "nequal", "possible"],
      "variables": ["a", "c", "e", "e1", "e2", "e3", "e4"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.7",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 300,
      "axiom_number": "(25.7)",
      "title": "Better explanation based on graded belief",
      "fol": "(forall (a e e1 e2 d1 d2) (if (and (agent a)(explain a e e1)(explain a e e2) (gbel a e1 d1)(gbel a e2 d2)(gt d1 d2)) (betterExplanationFor e1 e2 e a)))",
      "english": "One explanation is better than another for an agent if the agent has higher graded belief in it",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["agent", "explain", "gbel", "gt", "betterExplanationFor"],
      "variables": ["a", "e", "e1", "e2", "d1", "d2"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.8",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 301,
      "axiom_number": "(25.8)",
      "title": "Agents have preferred explanation domains",
      "fol": "(forall (a) (if (and (agent a)(etc)) (exists (d) (and (knowledgeDomain d) (forall (e e1 e2) (if (and (member e1 d)(not (member e2 d)) (explain a e e1)(explain a e e2)) (betterExplanationFor e1 e2 e a)))))))",
      "english": "Defeasibly, agents have preferred knowledge domains such that explanations in those domains are better than explanations outside them",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["agent", "etc", "knowledgeDomain", "member", "explain", "betterExplanationFor"],
      "variables": ["a", "d", "e", "e1", "e2"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.9",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 301,
      "axiom_number": "(25.9)",
      "title": "Definition of best explanation",
      "fol": "(forall (a e e1 s) (if (and (explain a e e1)(member e1 s) (forall (e2) (if (and (member e2 s)(explain a e e2) (nequal e1 e2)) (betterExplanationFor e1 e2 e a)))) (bestExplanationFor e1 e a s)))",
      "english": "An explanation is the best in a set if it is better than all other explanations in that set",
      "complexity": "complex",
      "pattern": "definition",
      "predicates": ["explain", "member", "nequal", "betterExplanationFor", "bestExplanationFor"],
      "variables": ["a", "e", "e1", "s", "e2"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.10",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.1",
      "page": 301,
      "axiom_number": "(25.10)",
      "title": "Best explanation causes belief in causation",
      "fol": "(forall (a e e1 e3 e4 s) (if (and (bestExplanationFor' e3 e1 e a s)(believe a e) (forall (e2) (iff (member e2 s)(explain a e e2))) (cause' e4 e1 e)(believe' e5 a e4)(etc)) (cause e3 e5)))",
      "english": "Defeasibly, if an explanation is the best among all possible explanations, this causes the agent to believe that explanation causes the explained eventuality",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["bestExplanationFor'", "believe", "member", "explain", "cause'", "believe'", "etc", "cause"],
      "variables": ["a", "e", "e1", "e3", "e4", "s", "e2", "e5"],
      "quantifiers": ["forall"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.11",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 302,
      "axiom_number": "(25.11)",
      "title": "Idealized explanation process breakdown",
      "fol": "(forall (a e e1) (if (and (explain a e e1)(etc)) (exists (e2 e3 e4 e5) (and (adoptGoalToExplain' e2 a e) (generateExplanations' e3 a e s) (assessExplanations' e4 a s e) (adoptExplanation' e5 a e1 e) (before e2 e3)(before e3 e4)(before e4 e5)))))",
      "english": "Defeasibly, the explanation process involves adopting a goal, generating candidates, assessing them, and adopting the best explanation, in that temporal order",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["explain", "etc", "adoptGoalToExplain'", "generateExplanations'", "assessExplanations'", "adoptExplanation'", "before"],
      "variables": ["a", "e", "e1", "e2", "e3", "e4", "e5", "s"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.12",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 302,
      "axiom_number": "(25.12)",
      "title": "Definition of adoptGoalToExplain",
      "fol": "(forall (a e) (iff (adoptGoalToExplain a e) (exists (e1 e2 e3) (and (changeTo e2)(goal' e2 e3 a) (explain' e3 a e e1)))))",
      "english": "To adopt a goal to explain e is to change into a state where one has the goal of explaining e",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["adoptGoalToExplain", "changeTo", "goal'", "explain'"],
      "variables": ["a", "e", "e1", "e2", "e3"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.13",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 302,
      "axiom_number": "(25.13)",
      "title": "Adopting explanation goal due to unpredicted events",
      "fol": "(forall (a e) (if (and (agent a)(learn a e)(not (predict a e))(etc)) (adoptGoalToExplain a e)))",
      "english": "A common reason for adopting a goal to explain something is that it had not been predicted",
      "complexity": "simple",
      "pattern": "defeasible_rule",
      "predicates": ["agent", "learn", "predict", "etc", "adoptGoalToExplain"],
      "variables": ["a", "e"],
      "quantifiers": ["forall"],
      "defeasible": true,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.14",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 302,
      "axiom_number": "(25.14)",
      "title": "Definition of generateExplanations",
      "fol": "(forall (a e s) (iff (generateExplanations a e s) (and (thinkOf a s) (forall (e1) (if (member e1 s) (and (explain a e e1)(possible e1 c) (cwu c a)))))))",
      "english": "To generate candidate explanations is to think of a set of eventualities that possibly cause the effect, given one's current world understanding",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["generateExplanations", "thinkOf", "member", "explain", "possible", "cwu"],
      "variables": ["a", "e", "s", "e1", "c"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.15",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 302,
      "axiom_number": "(25.15)",
      "title": "Definition of assessExplanations",
      "fol": "(forall (e0 a s e) (iff (assessExplanations' e0 a s e) (forall (e2) (if (member e2 e0) (exists (e3 e4 e5 e6) (and (changeTo' e2 e3)(believe' e3 a e4) (betterExplanationFor' e4 e5 e6 e a)))))))",
      "english": "To assess candidate explanations is to determine among various pairs which ones are better through belief formation about comparative quality",
      "complexity": "complex",
      "pattern": "definition",
      "predicates": ["assessExplanations'", "member", "changeTo'", "believe'", "betterExplanationFor'"],
      "variables": ["e0", "a", "s", "e", "e2", "e3", "e4", "e5", "e6"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.16",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 303,
      "axiom_number": "(25.16)",
      "title": "Definition of adoptExplanation",
      "fol": "(forall (a e1 e) (iff (adoptExplanation a e1 e) (exists (e2 e3) (and (changeTo e2)(believe' e2 a e3) (cause' e3 e1 e)))))",
      "english": "To adopt e1 as an explanation for e is to come to believe that e1 is the cause of e",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["adoptExplanation", "changeTo", "believe'", "cause'"],
      "variables": ["a", "e1", "e", "e2", "e3"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.17",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 303,
      "axiom_number": "(25.17)",
      "title": "Definition of rejectExplanation",
      "fol": "(forall (a e1 e) (iff (rejectExplanation a e1 e) (exists (e2 e3 e4) (and (changeTo e2)(believe' e2 a e3)(not' e3 e4) (cause' e4 e1 e)))))",
      "english": "To reject an explanation e1 for e is to change into a state where one believes that e1 does not cause e",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["rejectExplanation", "changeTo", "believe'", "not'", "cause'"],
      "variables": ["a", "e1", "e", "e2", "e3", "e4"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.18",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.2",
      "page": 303,
      "axiom_number": "(25.18)",
      "title": "Adopting explanation causes rejecting alternatives",
      "fol": "(forall (a e s e1 e2 e3) (if (and (agent a)(generateExplanations a e s) (adoptExplanation' e3 a e1 e)(member e1 s) (member e2 s)(nequal e2 e1)(etc)) (exists (e4) (and (rejectExplanation' e4 a e2 e)(cause e3 e4)))))",
      "english": "Defeasibly, adopting one explanation causes an agent to reject other explanations from the same generated set",
      "complexity": "complex",
      "pattern": "defeasible_rule",
      "predicates": ["agent", "generateExplanations", "adoptExplanation'", "member", "nequal", "etc", "rejectExplanation'", "cause"],
      "variables": ["a", "e", "s", "e1", "e2", "e3", "e4"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.19",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.3",
      "page": 303,
      "axiom_number": "(25.19)",
      "title": "Definition of explanationFailure",
      "fol": "(forall (a e) (iff (explanationFailure a e) (forall (e1 e2) (if (and (try a e2)(explain' e2 a e e1)) (fail a e2)))))",
      "english": "An explanation failure occurs exactly when every explanation attempt fails",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["explanationFailure", "try", "explain'", "fail"],
      "variables": ["a", "e", "e1", "e2"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "25.20",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.3",
      "page": 304,
      "axiom_number": "(25.20)",
      "title": "Failure to generate explanations",
      "fol": "(forall (a e s) (if (and (adoptGoalToExplain a e) (generateExplanations a e s)(null s)) (explanationFailure a e)))",
      "english": "If the agent adopts the goal to explain but generates no candidate explanations, there is an explanation failure",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["adoptGoalToExplain", "generateExplanations", "null", "explanationFailure"],
      "variables": ["a", "e", "s"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.21",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.3",
      "page": 304,
      "axiom_number": "(25.21)",
      "title": "Failure to assess explanations",
      "fol": "(forall (a e s) (if (and (adoptGoalToExplain a e) (generateExplanations a e s) (not (assessExplanations a s e))) (explanationFailure a e)))",
      "english": "If the agent generates candidates but does not assess them, there is an explanation failure",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["adoptGoalToExplain", "generateExplanations", "assessExplanations", "explanationFailure"],
      "variables": ["a", "e", "s"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "25.22",
      "chapter": 25,
      "chapter_title": "Explanation",
      "section": "25.3",
      "page": 304,
      "axiom_number": "(25.22)",
      "title": "Failure to adopt explanation",
      "fol": "(forall (a e s) (if (and (adoptGoalToExplain a e) (generateExplanations a e s) (assessExplanations a s e) (not (adoptExplanation a e1 e))) (explanationFailure a e)))",
      "english": "If the agent generates and assesses candidates but does not adopt an explanation, there is an explanation failure",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["adoptGoalToExplain", "generateExplanations", "assessExplanations", "adoptExplanation", "explanationFailure"],
      "variables": ["a", "e", "s", "e1"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    }
  ],
  "pattern_distribution": {
    "definition": 11,
    "defeasible_rule": 6,
    "existence_claim": 3,
    "type_constraint": 0,
    "axiom_schema": 0,
    "logical_conjunction": 0,
    "ordering_definition": 0,
    "function_definition": 0,
    "recursive_definition": 0,
    "belief_logic": 0,
    "goal_reasoning": 2,
    "emotion_causation": 0,
    "action_planning": 0
  },
  "complexity_distribution": {
    "simple": 6,
    "moderate": 8,
    "complex": 8
  },
  "domain_distribution": {
    "background_theory": 0,
    "psychology": 22,
    "example": 0
  },
  "predicate_frequency": {
    "agent": 7,
    "explain": 8,
    "explain'": 8,
    "etc": 6,
    "adoptGoalToExplain": 4,
    "generateExplanations": 4,
    "assessExplanations": 3,
    "adoptExplanation": 3,
    "rejectExplanation": 2,
    "explanationFailure": 4,
    "mystery": 2,
    "betterExplanationFor": 4,
    "bestExplanationFor": 2,
    "changeTo": 4,
    "believe": 2,
    "believe'": 4,
    "cause": 2,
    "cause'": 4,
    "goal'": 1,
    "member": 6,
    "possible": 3,
    "cwu": 3,
    "person": 2,
    "eventuality": 1,
    "able": 2,
    "nequal": 3,
    "gbel": 2,
    "gt": 1,
    "knowledgeDomain": 1,
    "before": 4,
    "thinkOf": 1,
    "changeTo'": 1,
    "not'": 1,
    "try": 1,
    "fail": 1,
    "null": 1,
    "learn": 1,
    "predict": 1
  },
  "conversion_notes": {
    "reified_predicates": "Extensive use of primed predicates for explanation processes: explain', adoptGoalToExplain', generateExplanations', assessExplanations', adoptExplanation', rejectExplanation', bestExplanationFor', cause', believe', goal', changeTo', not'",
    "defeasible_reasoning": "6 axioms use (etc) conditions for non-monotonic reasoning about explanation processes and agent behaviors",
    "explanation_process": "Chapter provides detailed process model with temporal ordering using before predicate",
    "cross_references": "References Chapter 21 (knowledgeDomain, gbel), Chapter 24 (explain definition), Chapter 28 (goal, try, fail predicates)",
    "technical_complexity": "Sophisticated process model with failure analysis at each stage of explanation generation and adoption"
  },
  "file_format_notes": {
    "axiom_extraction": "All 22 axioms successfully extracted with proper FOL syntax",
    "complexity_classification": "Based on quantifier depth, logical structure complexity, and number of conditions",
    "pattern_recognition": "Focused on explanation-specific patterns: process definitions, failure conditions, preference mechanisms",
    "reification_detection": "Systematic identification of primed predicates for cognitive processes and state changes"
  }
}