{
  "metadata": {
    "title": "A Formal Theory of Commonsense Psychology: How People Think People Think",
    "authors": "Andrew S. Gordon and Jerry R. Hobbs",
    "publisher": "Cambridge University Press",
    "year": 2017,
    "chapter": 27,
    "chapter_title": "Other-Agent Reasoning",
    "extraction_date": "2025-01-08",
    "axiom_count": 8,
    "description": "Chapter 27 axioms covering theory of mind, introspection, other-agent reasoning, and mental state models",
    "notation": "First-order logic with reified eventualities and causal system reasoning"
  },
  "axioms": [
    {
      "id": "27.1",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 309,
      "axiom_number": "(27.1)",
      "title": "Definition of envisionMentalState",
      "fol": "(forall (a b e) (iff (envisionMentalState a b e) (exists (s s1 x) (and (ecs s a)(thinkOf' e b x)(eventualitiesOf s1 s) (member e s1)))))",
      "english": "Agent a envisions agent b's mental state e if a envisions a causal system s, and if e is b's thinking of something x, and e is a member of s's set of eventualities",
      "complexity": "moderate",
      "pattern": "definition",
      "predicates": ["envisionMentalState", "ecs", "thinkOf'", "eventualitiesOf", "member"],
      "variables": ["a", "b", "e", "s", "s1", "x"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "27.2",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 309,
      "axiom_number": "(27.2)",
      "title": "People's ability to envision mental states",
      "fol": "(forall (a b e) (if (and (person a)(person b)(etc)) (exists (e1 c) (and (able a e1 c)(envisionMentalState' e1 a b e)))))",
      "english": "People are defeasibly able to envision other people's mental states, subject to implicit constraint conditions",
      "complexity": "moderate",
      "pattern": "defeasible_rule",
      "predicates": ["person", "etc", "able", "envisionMentalState'"],
      "variables": ["a", "b", "e", "e1", "c"],
      "quantifiers": ["forall", "exists"],
      "defeasible": true,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "27.3",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 309,
      "axiom_number": "(27.3)",
      "title": "Definition of otherAgentReason",
      "fol": "(forall (a b e) (iff (otherAgentReason a b e) (and (nequal a b)(envisionMentalState a b e))))",
      "english": "Other-agent reasoning is envisioning the mental state of someone other than the envisioning agent",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["otherAgentReason", "nequal", "envisionMentalState"],
      "variables": ["a", "b", "e"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "27.4",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 310,
      "axiom_number": "(27.4)",
      "title": "Definition of otherAgentReasonFail",
      "fol": "(forall (a b e) (iff (otherAgentReasonFail a b e) (exists (e1) (and (fail a e1)(otherAgentReason' e1 a b e)))))",
      "english": "People sometimes fail to envision the mental state of other people",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["otherAgentReasonFail", "fail", "otherAgentReason'"],
      "variables": ["a", "b", "e", "e1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "27.5",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 310,
      "axiom_number": "(27.5)",
      "title": "Definition of introspect",
      "fol": "(forall (a e) (iff (introspect a e)(envisionMentalState a a e)))",
      "english": "Introspection happens when one envisions one's own mental states",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["introspect", "envisionMentalState"],
      "variables": ["a", "e"],
      "quantifiers": ["forall"],
      "defeasible": false,
      "reified": false,
      "domain": "psychology"
    },
    {
      "id": "27.6",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 310,
      "axiom_number": "(27.6)",
      "title": "Definition of introspectFail",
      "fol": "(forall (a e) (iff (introspectFail a e) (exists (e1) (and (fail a e1)(introspect' e1 a e)))))",
      "english": "Introspection failure happens when an agent fails to introspect",
      "complexity": "simple",
      "pattern": "definition",
      "predicates": ["introspectFail", "fail", "introspect'"],
      "variables": ["a", "e", "e1"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "27.7",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 310,
      "axiom_number": "(27.7)",
      "title": "People have models of how others think",
      "fol": "(forall (a b) (if (and (person a)(person b)) (exists (s s1 e x) (and (causalSystem s)(eventualitiesOf s1 s)(member e s1) (thinkOf' e b x)(believe a s)))))",
      "english": "People have models of how people in general think - one agent has a belief in a causal system involving another agent's thinking",
      "complexity": "moderate",
      "pattern": "existence_claim",
      "predicates": ["person", "causalSystem", "eventualitiesOf", "member", "thinkOf'", "believe"],
      "variables": ["a", "b", "s", "s1", "e", "x"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    },
    {
      "id": "27.8",
      "chapter": 27,
      "chapter_title": "Other-Agent Reasoning",
      "section": "27.1",
      "page": 310,
      "axiom_number": "(27.8)",
      "title": "People have models of group thinking",
      "fol": "(forall (a) (if (person a) (exists (g) (forall (b) (if (member b g) (exists (s s1 e x) (and (causalSystem s)(eventualitiesOf s1 s) (member e s1)(thinkOf' e b x) (believe a s))))))))",
      "english": "More specifically, people have models of how members of certain groups think",
      "complexity": "complex",
      "pattern": "existence_claim",
      "predicates": ["person", "member", "causalSystem", "eventualitiesOf", "thinkOf'", "believe"],
      "variables": ["a", "g", "b", "s", "s1", "e", "x"],
      "quantifiers": ["forall", "exists"],
      "defeasible": false,
      "reified": true,
      "domain": "psychology"
    }
  ],
  "pattern_distribution": {
    "definition": 6,
    "defeasible_rule": 1,
    "existence_claim": 2,
    "type_constraint": 0,
    "axiom_schema": 0,
    "logical_conjunction": 0,
    "logical_disjunction": 0,
    "ordering_definition": 0,
    "function_definition": 0,
    "recursive_definition": 0,
    "belief_logic": 0,
    "goal_reasoning": 0,
    "emotion_causation": 0,
    "action_planning": 0,
    "argument_structure": 0
  },
  "complexity_distribution": {
    "simple": 4,
    "moderate": 3,
    "complex": 1
  },
  "domain_distribution": {
    "background_theory": 0,
    "psychology": 8,
    "example": 0
  },
  "predicate_frequency": {
    "envisionMentalState": 3,
    "envisionMentalState'": 1,
    "otherAgentReason": 1,
    "otherAgentReason'": 1,
    "otherAgentReasonFail": 1,
    "introspect": 1,
    "introspect'": 1,
    "introspectFail": 1,
    "ecs": 1,
    "thinkOf'": 3,
    "eventualitiesOf": 3,
    "member": 4,
    "person": 4,
    "etc": 1,
    "able": 1,
    "nequal": 1,
    "fail": 2,
    "causalSystem": 2,
    "believe": 2
  },
  "conversion_notes": {
    "reified_predicates": "Limited use of primed predicates for mental state processes: thinkOf', envisionMentalState', otherAgentReason', introspect'",
    "defeasible_reasoning": "Only 1 axiom uses (etc) conditions - minimal defeasible reasoning, focus on definitional framework",
    "theory_of_mind": "Formal treatment of theory of mind through causal system envisioning and mental state modeling",
    "cross_references": "References Chapter 24 (ecs, causal systems), Chapter 28 (fail predicate), Chapter 21 (believe)",
    "technical_complexity": "Relatively straightforward definitional framework building on established causal system infrastructure"
  },
  "file_format_notes": {
    "axiom_extraction": "All 8 axioms successfully extracted with proper FOL syntax",
    "complexity_classification": "Based on quantifier depth and causal system integration complexity",
    "pattern_recognition": "Primarily definitional (6/8) with existence claims for mental models and single defeasible rule",
    "reification_detection": "Systematic identification of primed predicates for theory of mind processes"
  }
}